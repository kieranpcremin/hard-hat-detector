{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Exploration & Understanding\n",
        "\n",
        "This notebook covers:\n",
        "1. Downloading the dataset\n",
        "2. Exploring the images\n",
        "3. Understanding data distribution\n",
        "4. Visualizing augmentations\n",
        "5. Testing our dataset class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import our libraries and set up paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path so we can import our modules\n",
        "sys.path.append(str(Path.cwd().parent / 'src'))\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# Set up matplotlib\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Download\n",
        "\n",
        "We'll use a hard hat detection dataset. There are several options:\n",
        "\n",
        "### Option A: Kaggle Dataset\n",
        "1. Go to: https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection\n",
        "2. Download and extract to `data/` folder\n",
        "\n",
        "### Option B: Roboflow Dataset\n",
        "1. Go to: https://universe.roboflow.com/search?q=hard+hat+classification\n",
        "2. Find a classification dataset (not object detection)\n",
        "3. Download in folder structure format\n",
        "\n",
        "### Expected Structure\n",
        "```\n",
        "data/\n",
        "├── train/\n",
        "│   ├── hard_hat/\n",
        "│   │   ├── img001.jpg\n",
        "│   │   └── ...\n",
        "│   └── no_hard_hat/\n",
        "│       ├── img001.jpg\n",
        "│       └── ...\n",
        "└── val/\n",
        "    ├── hard_hat/\n",
        "    └── no_hard_hat/\n",
        "```\n",
        "\n",
        "If your dataset has a different structure, we'll reorganize it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths\n",
        "DATA_DIR = Path.cwd().parent / 'data'\n",
        "TRAIN_DIR = DATA_DIR / 'train'\n",
        "VAL_DIR = DATA_DIR / 'val'\n",
        "\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Exists: {DATA_DIR.exists()}\")\n",
        "\n",
        "# Check what we have\n",
        "if DATA_DIR.exists():\n",
        "    print(\"\\nContents:\")\n",
        "    for item in DATA_DIR.iterdir():\n",
        "        print(f\"  {item.name}/\" if item.is_dir() else f\"  {item.name}\")\n",
        "else:\n",
        "    print(\"\\n⚠️ Data directory not found. Please download the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Explore the Images\n",
        "\n",
        "Let's look at some sample images from each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images_from_folder(folder_path, num_images=5, title=\"Images\"):\n",
        "    \"\"\"\n",
        "    Display sample images from a folder.\n",
        "    \n",
        "    Args:\n",
        "        folder_path: Path to folder containing images\n",
        "        num_images: Number of images to display\n",
        "        title: Title for the plot\n",
        "    \"\"\"\n",
        "    folder = Path(folder_path)\n",
        "    if not folder.exists():\n",
        "        print(f\"Folder not found: {folder}\")\n",
        "        return\n",
        "    \n",
        "    # Get image files\n",
        "    image_files = list(folder.glob('*.jpg')) + list(folder.glob('*.png'))\n",
        "    image_files = image_files[:num_images]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(f\"No images found in {folder}\")\n",
        "        return\n",
        "    \n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, len(image_files), figsize=(3*len(image_files), 3))\n",
        "    if len(image_files) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for ax, img_path in zip(axes, image_files):\n",
        "        img = Image.open(img_path)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f\"{img.size[0]}x{img.size[1]}\")\n",
        "    \n",
        "    fig.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show samples from each class\n",
        "if TRAIN_DIR.exists():\n",
        "    show_images_from_folder(TRAIN_DIR / 'hard_hat', title=\"HARD HAT - Training Samples\")\n",
        "    show_images_from_folder(TRAIN_DIR / 'no_hard_hat', title=\"NO HARD HAT - Training Samples\")\n",
        "else:\n",
        "    print(\"Please download the dataset first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Distribution\n",
        "\n",
        "Let's check the class balance - we want roughly equal numbers of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images(folder):\n",
        "    \"\"\"Count images in a folder.\"\"\"\n",
        "    folder = Path(folder)\n",
        "    if not folder.exists():\n",
        "        return 0\n",
        "    return len(list(folder.glob('*.jpg')) + list(folder.glob('*.png')))\n",
        "\n",
        "# Count images in each split/class\n",
        "if DATA_DIR.exists():\n",
        "    stats = {\n",
        "        'train_hard_hat': count_images(TRAIN_DIR / 'hard_hat'),\n",
        "        'train_no_hard_hat': count_images(TRAIN_DIR / 'no_hard_hat'),\n",
        "        'val_hard_hat': count_images(VAL_DIR / 'hard_hat'),\n",
        "        'val_no_hard_hat': count_images(VAL_DIR / 'no_hard_hat'),\n",
        "    }\n",
        "    \n",
        "    print(\"Dataset Statistics:\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Training - Hard Hat:     {stats['train_hard_hat']:5d}\")\n",
        "    print(f\"Training - No Hard Hat:  {stats['train_no_hard_hat']:5d}\")\n",
        "    print(f\"Training - Total:        {stats['train_hard_hat'] + stats['train_no_hard_hat']:5d}\")\n",
        "    print()\n",
        "    print(f\"Validation - Hard Hat:     {stats['val_hard_hat']:5d}\")\n",
        "    print(f\"Validation - No Hard Hat:  {stats['val_no_hard_hat']:5d}\")\n",
        "    print(f\"Validation - Total:        {stats['val_hard_hat'] + stats['val_no_hard_hat']:5d}\")\n",
        "    \n",
        "    # Plot distribution\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    \n",
        "    # Training split\n",
        "    ax1.bar(['Hard Hat', 'No Hard Hat'], \n",
        "            [stats['train_hard_hat'], stats['train_no_hard_hat']],\n",
        "            color=['green', 'red'])\n",
        "    ax1.set_title('Training Set')\n",
        "    ax1.set_ylabel('Number of Images')\n",
        "    \n",
        "    # Validation split\n",
        "    ax2.bar(['Hard Hat', 'No Hard Hat'], \n",
        "            [stats['val_hard_hat'], stats['val_no_hard_hat']],\n",
        "            color=['green', 'red'])\n",
        "    ax2.set_title('Validation Set')\n",
        "    ax2.set_ylabel('Number of Images')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Data Augmentation\n",
        "\n",
        "Let's see what our data augmentation transforms do to images.\n",
        "Augmentation helps the model generalize by showing it varied versions of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import our dataset module\n",
        "from dataset import get_train_transforms, get_val_transforms, denormalize\n",
        "\n",
        "# Get a sample image\n",
        "sample_dir = TRAIN_DIR / 'hard_hat'\n",
        "if sample_dir.exists():\n",
        "    sample_images = list(sample_dir.glob('*.jpg'))\n",
        "    if sample_images:\n",
        "        sample_path = sample_images[0]\n",
        "        original_image = Image.open(sample_path)\n",
        "        print(f\"Sample image: {sample_path.name}\")\n",
        "        print(f\"Original size: {original_image.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_augmentations(image, transform, num_samples=6):\n",
        "    \"\"\"\n",
        "    Show multiple augmented versions of the same image.\n",
        "    \n",
        "    This demonstrates how random augmentation creates variety.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, ax in enumerate(axes):\n",
        "        # Apply transform (random augmentation each time)\n",
        "        augmented = transform(image)\n",
        "        \n",
        "        # Denormalize for visualization\n",
        "        augmented = denormalize(augmented)\n",
        "        \n",
        "        # Convert to numpy for display\n",
        "        # Tensor shape: (C, H, W) -> numpy shape: (H, W, C)\n",
        "        augmented_np = augmented.permute(1, 2, 0).numpy()\n",
        "        augmented_np = np.clip(augmented_np, 0, 1)  # Clip to valid range\n",
        "        \n",
        "        ax.imshow(augmented_np)\n",
        "        ax.set_title(f\"Augmented #{i+1}\")\n",
        "        ax.axis('off')\n",
        "    \n",
        "    fig.suptitle(\"Same image with different random augmentations\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if 'original_image' in dir():\n",
        "    train_transform = get_train_transforms()\n",
        "    show_augmentations(original_image, train_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Dataset Class\n",
        "\n",
        "Let's test our custom PyTorch Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataset import HardHatDataset, create_dataloaders\n",
        "\n",
        "# Create dataset\n",
        "if TRAIN_DIR.exists():\n",
        "    train_dataset = HardHatDataset(\n",
        "        root_dir=str(TRAIN_DIR),\n",
        "        transform=get_train_transforms()\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nDataset size: {len(train_dataset)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a sample\n",
        "if 'train_dataset' in dir() and len(train_dataset) > 0:\n",
        "    image, label = train_dataset[0]\n",
        "    \n",
        "    print(\"Sample from dataset:\")\n",
        "    print(f\"  Image shape: {image.shape}\")  # Should be (3, 224, 224)\n",
        "    print(f\"  Label: {label} ({train_dataset.CLASSES[label]})\")\n",
        "    print(f\"  Pixel value range: [{image.min():.2f}, {image.max():.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test DataLoader\n",
        "if DATA_DIR.exists():\n",
        "    train_loader, val_loader = create_dataloaders(\n",
        "        data_dir=str(DATA_DIR),\n",
        "        batch_size=16\n",
        "    )\n",
        "    \n",
        "    # Get a batch\n",
        "    images, labels = next(iter(train_loader))\n",
        "    \n",
        "    print(f\"\\nBatch from DataLoader:\")\n",
        "    print(f\"  Images shape: {images.shape}\")  # Should be (16, 3, 224, 224)\n",
        "    print(f\"  Labels shape: {labels.shape}\")  # Should be (16,)\n",
        "    print(f\"  Labels: {labels.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize a Batch\n",
        "\n",
        "Let's display a batch of images with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_batch(images, labels, class_names, num_images=8):\n",
        "    \"\"\"\n",
        "    Display a batch of images with their labels.\n",
        "    \n",
        "    Args:\n",
        "        images: Batch of image tensors (B, C, H, W)\n",
        "        labels: Batch of labels (B,)\n",
        "        class_names: List of class names\n",
        "        num_images: Number of images to display\n",
        "    \"\"\"\n",
        "    num_images = min(num_images, len(images))\n",
        "    \n",
        "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 7))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, ax in enumerate(axes[:num_images]):\n",
        "        # Denormalize\n",
        "        img = denormalize(images[i])\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        # Get label\n",
        "        label_idx = labels[i].item()\n",
        "        label_name = class_names[label_idx]\n",
        "        \n",
        "        # Plot\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(label_name, color='green' if label_idx == 1 else 'red')\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.suptitle(\"Training Batch Sample\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if 'train_loader' in dir():\n",
        "    images, labels = next(iter(train_loader))\n",
        "    show_batch(images, labels, HardHatDataset.CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook we:\n",
        "\n",
        "1. **Downloaded/located** the hard hat dataset\n",
        "2. **Explored** sample images from each class\n",
        "3. **Analyzed** class distribution (checking for imbalance)\n",
        "4. **Visualized** data augmentation transforms\n",
        "5. **Tested** our custom Dataset and DataLoader classes\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Now that we understand our data, we can move on to:\n",
        "1. Model creation (see `src/model.py`)\n",
        "2. Training (see `src/train.py`)\n",
        "3. Inference (see `src/inference.py`)\n",
        "\n",
        "To train the model, run:\n",
        "```bash\n",
        "cd src\n",
        "python train.py --data_dir ../data --epochs 10\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
